# 1-3 선형 회귀 모델 구현하기
### 선형회귀
![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Linear-svm-scatterplot.svg/1080px-Linear-svm-scatterplot.svg.png)
> 선형 회귀(線型回歸, 영어: linear regression)는 종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법이다. 한 개의 설명 변수에 기반한 경우에는 단순 선형 회귀, 둘 이상의 설명 변수에 기반한 경우에는 다중 선형 회귀라고 한다.[참고 1]  
> 선형 회귀는 선형 예측 함수를 사용해 회귀식을 모델링하며, 알려지지 않은 파라미터는 데이터로부터 추정한다. 이렇게 만들어진 회귀식을 선형 모델이라고 한다.  
> 선형 회귀는 깊이있게 연구되고 널리 사용된 첫 번째 회귀분석 기법이다.[3] 이는 알려지지 않은 파라미터에 대해 선형 관계를 갖는 모델을 세우는 것이, 비선형 관계를 갖는 모델을 세우는 것보다 용이하기 때문이다.  
> 선형 회귀는 여러 사용 사례가 있지만, 대개 아래와 같은 두 가지 분류 중 하나로 요약할 수 있다.  
> * 값을 예측하는 것이 목적일 경우, 선형 회귀를 사용해 데이터에 적합한 예측 모형을 개발한다. 개발한 선형 회귀식을 사용해 y가 없는 x값에 대해 y를 예측하기 위해 사용할 수 있다.  
> * 종속 변수 y와 이것과 연관된 독립 변수 X1, ..., Xp가 존재하는 경우에, 선형 회귀 분석을 사용해 Xj와 y의 관계를 정량화할 수 있다. Xj는 y와 전혀 관계가 없을 수도 있고, 추가적인 정보를 제공하는 변수일 수도 있다.  
> 일반적으로 최소제곱법(least square method)을 사용해 선형 회귀 모델을 세운다. 최소제곱법 외에 다른 기법으로도 선형 회귀 모델을 세울 수 있다. 손실 함수(loss fuction)를 최소화 하는 방식으로 선형 회귀 모델을 세울 수도 있다. 최소제곱법은 선형 회귀 모델 뿐 아니라, 비선형 회귀 모델에도 적용할 수 있다. 최소제곱법과 선형 회귀는 가깝게 연관되어 있지만, 그렇다고 해서 동의어는 아니다.  
>  - [선형 회귀 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)  
* 주어진 x와 y값을 가지고 서로 간의 관계를 파악하는 것
* 선형회귀에서의 기본 수식
	* hypothesis = W * X + b
	* 가중치(W), 편향(b)
	* X가 주어졌을 때, Y를 만들어 낼 수 있는 W, b를 찾아낼 것
#### 🌼입력에 대한 출력을 예측하는 것 -> 머신러닝의 기본

###  균등 분포(uniform distribution)란?
균등 분포는 연속 균등 분포와 이산 균등 분포의 뜻으로 쓰인다.
#### 연속 균등 분포
![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Uniform_distribution_PDF.png/405px-Uniform_distribution_PDF.png)
> 연속균등분포(continuous uniform distribution)은 연속 확률 분포로, 분포가 특정 범위 내에서 균등하게 나타나 있을 경우를 가리킨다. 이 분포는 두 개의 매개변수 {\displaystyle a,b} a,b를 받으며, 이때 {\displaystyle [a,b]} [a,b] 범위에서 균등한 확률을 가진다. 보통 기호로 {\displaystyle {\mathcal {U}}(a,b)} {\displaystyle {\mathcal {U}}(a,b)}로 나타낸다.  
>  - [연속균등분포 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%97%B0%EC%86%8D%EA%B7%A0%EB%93%B1%EB%B6%84%ED%8F%AC)  
#### 이산 균등 분포
![]](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/DUniform_distribution_PDF.png/405px-DUniform_distribution_PDF.png)
> 이산균등분포(discrete uniform distribution)란, 확률론과 통계학에서 다루는 이산확률분포중 확률분포 함수가 정의된 모든 곳에서 그 값이 일정한 분포를 말한다.  
> 만일 확률변수가 {\displaystyle k_{1},k_{2},\dots ,k_{n}} k_{1},k_{2},\dots ,k_{n}과 같이 {\displaystyle n} n개의 값을 가질 수 있다면, 이 분포는 이산균등분포가 된다. 이 때, {\displaystyle k_{i}} k_i 일 확률은 {\displaystyle {\frac {1}{n}}} {\frac  1n}이 된다. 이산균등분포의 가장 대표적인 예는 모든 면이 나올 확률이 동등한 주사위이다. 예를 들어 1, 2, 3, 4, 5, 6의 값을 갖는 주사위라면, 이를 던졌을 때 각각의 눈이 나올 확률은 {\displaystyle {\frac {1}{6}}} {\frac  16}이다.  
> 이산균등분포의 확률 변수의 값이 실수인 경우, 이때 누적 분포 함수는 다음과 같이 퇴화분포의 합으로 표시가 된다. 헤비사이드 계단 함수 {\displaystyle H(x-x_{0})} H(x-x_{0})를 중심이 {\displaystyle x_{0}} x_0인 퇴화분포의 누적분포함수라 하면,  
> {\displaystyle F(k;a,b,n)={1 \over n}\sum _{i=1}^{n}H(k-k_{i})} F(k;a,b,n)={1 \over n}\sum _{{i=1}}^{n}H(k-k_{i})  
> 이 성립한다.  

### 손실함수(loss function)
> 통계학, 결정 이론 및 경제학 분야에서 손실 함수는 사건(기술적으로 표본 공간의 한 요소)을 그 사건과 관련된 경제적 손실을 표현하는 실수로 사상하는 함수이다. 손실 함수는 확률 변수의 정의를 만족하므로 누적 분포 함수와 예측치를 구할 수 있다.  
> - [손실 함수 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EC%86%90%EC%8B%A4_%ED%95%A8%EC%88%98)  
	* x, y 한 쌍의 데이터에 대한 손실값을 계산하는 함수
* 손실값
	* 실제 값과 모델로 예측한 값이 얼마나 차이가 나는지 나타냄
	* 손실값이 작을 수록 x, y에 대한 관계 예측을 잘 하고 있다는 것
	* (예측값 - 실제값)^2
* 비용
	* 손실값을 전체 데이터에 대해 구한 것
	* 모든 데이터에 대한 손실값의 평균
* 학습
	* 변수들의 값을 다양하게 넣어 계산해보면서 손실값을 최소화 하는 W와 b를 구하는 것

###  경사 하강법
![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Gradient_descent.png/330px-Gradient_descent.png)
경사 하강법을 실행하는 모습. {\displaystyle x_{0}} x_0에서 시작하여, 경사가 낮아지는 쪽으로 이동하여 차례대로 {\displaystyle x_{1},x_{2},x_{3},x_{4}} {\displaystyle x_{1},x_{2},x_{3},x_{4}}를 얻는다.
> 경사 하강법(傾斜下降法, Gradient descent)은 1차 근삿값 발견용 최적화 알고리즘이다. 기본 아이디어는 함수의 기울기(경사)를 구하여 기울기가 낮은 쪽으로 계속 이동시켜서 극값에 이를 때까지 반복시키는 것이다.  
> - [경사 하강법 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95)  
* 텐서플로가 기본 제공하는 경사 하강법 최적화 함수를 이용해 손실값을 최소화하는 연산 그래프를 생성할 수 있다.
	* 최적화 함수 : 가중치와 편향의 값을 변경해가면서 손실값을 최소화하는 가장 최적화된 가중치와 편향 값을 찾아주는 함수 
	* 모든 값을 변경하며 값을 찾는게 아니라 함수의 기울기를 구해서 기울기가 낮을 쪽으로 계속 이동하면서 최적값을 찾음
	* 경사 하강법 구현 : [Momentum & Nesterov momentum | 텐서 플로우 블로그 (Tensor ≈ Blog)](https://tensorflow.blog/2017/03/22/momentum-nesterov-momentum/)