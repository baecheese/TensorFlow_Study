# 2. 기본 신경망 구현
## 2.1 인공신경망의 작동 원리
![](http://study.zumst.com/upload/00-D22-91-12-05/1_2_a_%EB%89%B4%EB%9F%B0%EC%9D%98%20%EA%B5%AC%EC%A1%B0.jpg)
* 인공신경망(artificial neural network)은 뉴런의 동작원리에 기초
![](https://github.com/baecheese/TensorFlow_Study/blob/master/2.%20%EA%B8%B0%EB%B3%B8%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EA%B5%AC%ED%98%84/2-1%20%EC%9D%B8%EA%B3%B5%20%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98%20%EC%9E%91%EB%8F%99%20%EC%9B%90%EB%A6%AC/%EB%89%B4%EB%9F%B0%EA%B3%BC%20%EC%9D%B8%EA%B3%B5%EB%89%B4%EB%9F%B0%20%EA%B7%B8%EB%A0%A4%EB%B4%84.jpg?raw=true)
	* 인공 뉴런의 원리 : 입력 값 X에 가중치를 곱하고 편향을 더한 뒤 활성화 함수를 거쳐 결괏값 y를 만들어냄
	* y = sigmoid(X x W + b)
	* W(가중치)와 b(편향)을 찾아내는게 학습
	
### 활성화 함수
![](http://adilmoujahid.com/images/activation.png)
	* 활성화 함수는 인공 신경망을 통과해온 값을 최종적으로 어떤 값으로 만들지 결정한다

### 인공신경망
* 수천~수만개의 가중치와 편향 값의 조합을 일일이 변경하면서 계산하기에는 어려움이 있다
![인공신경망 / hidden layer = 은닉층](https://cdn-images-1.medium.com/max/1600/1*W_tihAB4BvLHw43CMXv_Sw.png)
* 제프리 힌튼 교수의 **제한된 볼트만 머신**
	* 이 신경망 학습 알고리즘을 통해 심층 신경망을 효율적으로 학습 시킬 수 있음이 증명됨
	* -> 이후 드롭아웃 기법, ReLU 등의 활성화 함수들 개발
	* -> 요즘의 GPU 발전이 딥러닝에 도움
	
###  역전파
![](http://cfile207.uf.daum.net/R400x0/177EEE434FA8047A02B6A8)
* 출력층이 내놓은 결과의 오차를 신경망을 따라 입력층까지 역으로 전파하며 계산해나가는 방식
* 입력층부터 가중치를 조절해가는 기존 방식보다 훨씬 유의미한 방식으로 가중치를 조절해 최적화
* 텐서플로는 역전파 기법을 기본으로 제공해줌



